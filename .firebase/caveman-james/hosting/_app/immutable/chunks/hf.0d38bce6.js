var h=Object.defineProperty;var v=(r,t,e)=>t in r?h(r,t,{enumerable:!0,configurable:!0,writable:!0,value:e}):r[t]=e;var p=(r,t,e)=>(v(r,typeof t!="symbol"?t+"":t,e),e);import{E as A,b as _}from"./NavBar.6deeb84e.js";function d(r){return Array.isArray(r)?r:[r]}function O(r){let t,e,s,n=!1;return function(a){t===void 0?(t=a,e=0,s=-1):t=q(t,a);const o=t.length;let u=0;for(;e<o;){n&&(t[e]===10&&(u=++e),n=!1);let c=-1;for(;e<o&&c===-1;++e)switch(t[e]){case 58:s===-1&&(s=e-u);break;case 13:n=!0;case 10:c=e;break}if(c===-1)break;r(t.subarray(u,c),s),u=e,s=-1}u===o?t=void 0:u!==0&&(t=t.subarray(u),e-=u)}}function E(r,t,e){let s=b();const n=new TextDecoder;return function(a,o){if(a.length===0)e==null||e(s),s=b();else if(o>0){const u=n.decode(a.subarray(0,o)),c=o+(a[o+1]===32?2:1),l=n.decode(a.subarray(c));switch(u){case"data":s.data=s.data?s.data+`
`+l:l;break;case"event":s.event=l;break;case"id":r(s.id=l);break;case"retry":const y=parseInt(l,10);isNaN(y)||t(s.retry=y);break}}}}function q(r,t){const e=new Uint8Array(r.length+t.length);return e.set(r),e.set(t,r.length),e}function b(){return{data:"",event:"",id:"",retry:void 0}}var V="https://api-inference.huggingface.co/models/",m=(r=>(r.Length="length",r.EndOfSequenceToken="eos_token",r.StopSequence="stop_sequence",r))(m||{}),g=class{constructor(r="",t={}){p(this,"apiKey");p(this,"defaultOptions");this.apiKey=r,this.defaultOptions=t}async fillMask(r,t){const e=await this.request(r,t);if(!(Array.isArray(e)&&e.every(n=>typeof n.score=="number"&&typeof n.sequence=="string"&&typeof n.token=="number"&&typeof n.token_str=="string")))throw new TypeError("Invalid inference output: output must be of type Array<score: number, sequence:string, token:number, token_str:string>");return e}async summarization(r,t){const e=await this.request(r,t);if(!(Array.isArray(e)&&e.every(n=>typeof n.summary_text=="string")))throw new TypeError("Invalid inference output: output must be of type Array<summary_text: string>");return e==null?void 0:e[0]}async questionAnswer(r,t){const e=await this.request(r,t);if(!(typeof e.answer=="string"&&typeof e.end=="number"&&typeof e.score=="number"&&typeof e.start=="number"))throw new TypeError("Invalid inference output: output must be of type <answer: string, end: number, score: number, start: number>");return e}async tableQuestionAnswer(r,t){const e=await this.request(r,t);if(!(typeof e.aggregator=="string"&&typeof e.answer=="string"&&Array.isArray(e.cells)&&e.cells.every(n=>typeof n=="string")&&Array.isArray(e.coordinates)&&e.coordinates.every(n=>Array.isArray(n)&&n.every(i=>typeof i=="number"))))throw new TypeError("Invalid inference output: output must be of type <aggregator: string, answer: string, cells: string[], coordinates: number[][]>");return e}async textClassification(r,t){var n;const e=(n=await this.request(r,t))==null?void 0:n[0];if(!(Array.isArray(e)&&e.every(i=>typeof i.label=="string"&&typeof i.score=="number")))throw new TypeError("Invalid inference output: output must be of type Array<label: string, score: number>");return e}async textGeneration(r,t){const e=await this.request(r,t);if(!(Array.isArray(e)&&e.every(n=>typeof n.generated_text=="string")))throw new TypeError("Invalid inference output: output must be of type Array<generated_text: string>");return e==null?void 0:e[0]}async*textGenerationStream(r,t){yield*this.streamingRequest(r,t)}async tokenClassification(r,t){const e=d(await this.request(r,t));if(!(Array.isArray(e)&&e.every(n=>typeof n.end=="number"&&typeof n.entity_group=="string"&&typeof n.score=="number"&&typeof n.start=="number"&&typeof n.word=="string")))throw new TypeError("Invalid inference output: output must be of type Array<end: number, entity_group: string, score: number, start: number, word: string>");return e}async translation(r,t){const e=await this.request(r,t);if(!(Array.isArray(e)&&e.every(n=>typeof n.translation_text=="string")))throw new TypeError("Invalid inference output: output must be of type Array<translation_text: string>");return e==null?void 0:e[0]}async zeroShotClassification(r,t){const e=d(await this.request(r,t));if(!(Array.isArray(e)&&e.every(n=>Array.isArray(n.labels)&&n.labels.every(i=>typeof i=="string")&&Array.isArray(n.scores)&&n.scores.every(i=>typeof i=="number")&&typeof n.sequence=="string")))throw new TypeError("Invalid inference output: output must be of type Array<labels: string[], scores: number[], sequence: string>");return e}async conversational(r,t){const e=await this.request(r,t);if(!(Array.isArray(e.conversation.generated_responses)&&e.conversation.generated_responses.every(n=>typeof n=="string")&&Array.isArray(e.conversation.past_user_inputs)&&e.conversation.past_user_inputs.every(n=>typeof n=="string")&&typeof e.generated_text=="string"&&Array.isArray(e.warnings)&&e.warnings.every(n=>typeof n=="string")))throw new TypeError("Invalid inference output: output must be of type <conversation: {generated_responses: string[], past_user_inputs: string[]}, generated_text: string, warnings: string[]>");return e}async featureExtraction(r,t){return await this.request(r,t)}async automaticSpeechRecognition(r,t){const e=await this.request(r,{...t,binary:!0});if(!(typeof e.text=="string"))throw new TypeError("Invalid inference output: output must be of type <text: string>");return e}async audioClassification(r,t){const e=await this.request(r,{...t,binary:!0});if(!(Array.isArray(e)&&e.every(n=>typeof n.label=="string"&&typeof n.score=="number")))throw new TypeError("Invalid inference output: output must be of type Array<label: string, score: number>");return e}async imageClassification(r,t){const e=await this.request(r,{...t,binary:!0});if(!(Array.isArray(e)&&e.every(n=>typeof n.label=="string"&&typeof n.score=="number")))throw new TypeError("Invalid inference output: output must be of type Array<label: string, score: number>");return e}async objectDetection(r,t){const e=await this.request(r,{...t,binary:!0});if(!(Array.isArray(e)&&e.every(n=>typeof n.label=="string"&&typeof n.score=="number"&&typeof n.box.xmin=="number"&&typeof n.box.ymin=="number"&&typeof n.box.xmax=="number"&&typeof n.box.ymax=="number")))throw new TypeError("Invalid inference output: output must be of type Array<{label:string; score:number; box:{xmin:number; ymin:number; xmax:number; ymax:number}}>");return e}async imageSegmentation(r,t){const e=await this.request(r,{...t,binary:!0});if(!(Array.isArray(e)&&e.every(n=>typeof n.label=="string"&&typeof n.mask=="string"&&typeof n.score=="number")))throw new TypeError("Invalid inference output: output must be of type Array<label: string, mask: string, score: number>");return e}async textToImage(r,t){const e=await this.request(r,{...t,blob:!0});if(!(e&&e instanceof Blob))throw new TypeError("Invalid inference output: output must be of type object & of instance Blob");return e}async imageToText(r,t){var e;return(e=await this.request(r,{...t,binary:!0}))==null?void 0:e[0]}makeRequestOptions(r,t){const e={...this.defaultOptions,...t},{model:s,...n}=r,i={};this.apiKey&&(i.Authorization=`Bearer ${this.apiKey}`),t!=null&&t.binary||(i["Content-Type"]="application/json"),t!=null&&t.binary&&(e.wait_for_model&&(i["X-Wait-For-Model"]="true"),e.use_cache===!1&&(i["X-Use-Cache"]="false"),e.dont_load_model&&(i["X-Load-Model"]="0"));const a=`${V}${s}`,o={headers:i,method:"POST",body:t!=null&&t.binary?r.data:JSON.stringify({...n,options:e}),credentials:t!=null&&t.includeCredentials?"include":"same-origin"};return{url:a,info:o,mergedOptions:e}}async request(r,t){const{url:e,info:s,mergedOptions:n}=this.makeRequestOptions(r,t),i=await fetch(e,s);if(n.retry_on_error!==!1&&i.status===503&&!n.wait_for_model)return this.request(r,{...n,wait_for_model:!0});if(t!=null&&t.blob){if(!i.ok)throw new Error("An error occurred while fetching the blob");return await i.blob()}const a=await i.json();if(a.error)throw new Error(a.error);return a}async*streamingRequest(r,t){var l;const{url:e,info:s,mergedOptions:n}=this.makeRequestOptions({...r,stream:!0},t),i=await fetch(e,s);if(n.retry_on_error!==!1&&i.status===503&&!n.wait_for_model)return this.streamingRequest(r,{...n,wait_for_model:!0});if(!i.ok){if((l=i.headers.get("Content-Type"))!=null&&l.startsWith("application/json")){const y=await i.json();if(y.error)throw new Error(y.error)}throw new Error(`Server response contains error: ${i.status}`)}if(i.headers.get("content-type")!=="text/event-stream")throw new Error("Server does not support event stream content type, it returned "+i.headers.get("content-type"));if(!i.body)return;const a=i.body.getReader();let o=[];const c=O(E(()=>{},()=>{},y=>{o.push(y)}));try{for(;;){const{done:y,value:w}=await a.read();if(y)return;c(w);for(const f of o)f.data.length>0&&(yield JSON.parse(f.data));o=[]}}finally{a.releaseLock()}}};const T=Object.freeze(Object.defineProperty({__proto__:null,HfInference:g,TextGenerationStreamFinishReason:m},Symbol.toStringTag,{value:"Module"}));class S extends A{constructor(t){super(t??{}),Object.defineProperty(this,"apiKey",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"model",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),Object.defineProperty(this,"client",{enumerable:!0,configurable:!0,writable:!0,value:void 0}),this.model=(t==null?void 0:t.model)??"sentence-transformers/distilbert-base-nli-mean-tokens",this.apiKey=(t==null?void 0:t.apiKey)??_("HUGGINGFACEHUB_API_KEY"),this.client=new g(this.apiKey)}async _embed(t){const e=t.map(s=>s.replace(/\n/g," "));return this.caller.call(()=>this.client.featureExtraction({model:this.model,inputs:e}))}embedQuery(t){return this._embed([t]).then(e=>e[0])}embedDocuments(t){return this._embed(t)}}export{S as H,T as i};
